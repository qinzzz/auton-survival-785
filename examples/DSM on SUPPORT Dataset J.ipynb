{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSM on SUPPORT Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SUPPORT dataset comes from the Vanderbilt University study\n",
    "to estimate survival for seriously ill hospitalized adults.\n",
    "(Refer to http://biostat.mc.vanderbilt.edu/wiki/Main/SupportDesc.\n",
    "for the original datasource.)\n",
    "\n",
    "In this notebook, we will apply Deep Survival Machines for survival prediction on the SUPPORT data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the SUPPORT Dataset\n",
    "\n",
    "The package includes helper functions to load the dataset.\n",
    "\n",
    "X represents an np.array of features (covariates),\n",
    "T is the event/censoring times and,\n",
    "E is the censoring indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from auton_survival import datasets\n",
    "outcomes, features = datasets.load_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auton_survival.preprocessing import Preprocessor\n",
    "cat_feats = ['sex', 'dzgroup', 'dzclass', 'income', 'race', 'ca']\n",
    "num_feats = ['age', 'num.co', 'meanbp', 'wblc', 'hrt', 'resp', \n",
    "\t     'temp', 'pafi', 'alb', 'bili', 'crea', 'sod', 'ph', \n",
    "             'glucose', 'bun', 'urine', 'adlp', 'adls']\n",
    "\n",
    "features = Preprocessor().fit_transform(features, cat_feats=cat_feats, num_feats=num_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute horizons at which we evaluate the performance of DSM\n",
    "\n",
    "Survival predictions are issued at certain time horizons. Here we will evaluate the performance\n",
    "of DSM to issue predictions at the 25th, 50th and 75th event time quantile as is standard practice in Survival Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "horizons = [0.25, 0.5, 0.75]\n",
    "times = np.quantile(outcomes.time[outcomes.event==1], horizons).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train, test and validation sets\n",
    "\n",
    "We will train DSM on 70% of the Data, use a Validation set of 10% for Model Selection and report performance on the remaining 20% held out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, e = features.values, outcomes.time.values, outcomes.event.values\n",
    "\n",
    "n = len(x)\n",
    "\n",
    "tr_size = int(n*0.70)\n",
    "vl_size = int(n*0.10)\n",
    "te_size = int(n*0.20)\n",
    "\n",
    "x_train, x_test, x_val = x[:tr_size], x[-te_size:], x[tr_size:tr_size+vl_size]\n",
    "t_train, t_test, t_val = t[:tr_size], t[-te_size:], t[tr_size:tr_size+vl_size]\n",
    "e_train, e_test, e_val = e[:tr_size], e[-te_size:], e[tr_size:tr_size+vl_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the parameter grid\n",
    "\n",
    "Lets set up the parameter grid to tune hyper-parameters. We will tune the number of underlying survival distributions, \n",
    "($K$), the distribution choices (Log-Normal or Weibull), the learning rate for the Adam optimizer between $1\\times10^{-3}$ and $1\\times10^{-4}$ and the number of hidden layers between $0, 1$ and $2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'k' : [4, 6, 8],\n",
    "              'distribution' : ['LogNormal', 'Weibull'],\n",
    "              'discount': [0.5, 0.75, 1],\n",
    "              'learning_rate' : [1e-4, 1e-3],\n",
    "              'layers' : [ [], [100], [100, 100] ]\n",
    "              }\n",
    "params = ParameterGrid(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auton_survival.models.dsm import DeepSurvivalMachines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSurvivalMachines(k = 3, distribution = 'LogNormal', layers = [100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1190/10000 [00:01<00:14, 616.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start pretraining VAE ...\n",
      "Start training DSM + VAE ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:10<00:41,  1.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\oli30\\Desktop\\11785_Intro_to_DL\\project\\auton-survival-785\\examples\\DSM on SUPPORT Dataset J.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/examples/DSM%20on%20SUPPORT%20Dataset%20J.ipynb#ch0000016?line=2'>3</a>\u001b[0m     model \u001b[39m=\u001b[39m DeepSurvivalMachines(k \u001b[39m=\u001b[39m param[\u001b[39m'\u001b[39m\u001b[39mk\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/examples/DSM%20on%20SUPPORT%20Dataset%20J.ipynb#ch0000016?line=3'>4</a>\u001b[0m                                  distribution \u001b[39m=\u001b[39m param[\u001b[39m'\u001b[39m\u001b[39mdistribution\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/examples/DSM%20on%20SUPPORT%20Dataset%20J.ipynb#ch0000016?line=4'>5</a>\u001b[0m                                 \u001b[39m#  discount = param['discount'],\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/examples/DSM%20on%20SUPPORT%20Dataset%20J.ipynb#ch0000016?line=5'>6</a>\u001b[0m                                  layers \u001b[39m=\u001b[39m param[\u001b[39m'\u001b[39m\u001b[39mlayers\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/examples/DSM%20on%20SUPPORT%20Dataset%20J.ipynb#ch0000016?line=6'>7</a>\u001b[0m     \u001b[39m# The fit method is called to train the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/examples/DSM%20on%20SUPPORT%20Dataset%20J.ipynb#ch0000016?line=7'>8</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(x_train, t_train, e_train, iters \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, learning_rate \u001b[39m=\u001b[39;49m param[\u001b[39m'\u001b[39;49m\u001b[39mlearning_rate\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/examples/DSM%20on%20SUPPORT%20Dataset%20J.ipynb#ch0000016?line=8'>9</a>\u001b[0m     models\u001b[39m.\u001b[39mappend([[model\u001b[39m.\u001b[39mcompute_nll(x_val, t_val, e_val), model]])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/examples/DSM%20on%20SUPPORT%20Dataset%20J.ipynb#ch0000016?line=9'>10</a>\u001b[0m best_model \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(models)\n",
      "File \u001b[1;32mc:\\Users\\oli30\\Desktop\\11785_Intro_to_DL\\project\\auton-survival-785\\auton_survival\\models\\dsm\\__init__.py:228\u001b[0m, in \u001b[0;36mDSMBase.fit\u001b[1;34m(self, x, t, e, vsize, val_data, iters, learning_rate, batch_size, elbo, optimizer)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/__init__.py?line=225'>226</a>\u001b[0m maxrisk \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mnanmax(e_train\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()))\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/__init__.py?line=226'>227</a>\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gen_torch_model(inputdim, optimizer, risks\u001b[39m=\u001b[39mmaxrisk)\n\u001b[1;32m--> <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/__init__.py?line=227'>228</a>\u001b[0m model, _ \u001b[39m=\u001b[39m train_dsm(model,\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/__init__.py?line=228'>229</a>\u001b[0m                      x_train, t_train, e_train, x_train_normalized,\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/__init__.py?line=229'>230</a>\u001b[0m                      x_val, t_val, e_val, x_val_normalized,\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/__init__.py?line=230'>231</a>\u001b[0m                      n_iter\u001b[39m=\u001b[39;49miters,\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/__init__.py?line=231'>232</a>\u001b[0m                      lr\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/__init__.py?line=232'>233</a>\u001b[0m                      elbo\u001b[39m=\u001b[39;49melbo,\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/__init__.py?line=233'>234</a>\u001b[0m                      bs\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/__init__.py?line=234'>235</a>\u001b[0m                      random_seed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_seed)\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/__init__.py?line=236'>237</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtorch_model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/__init__.py?line=237'>238</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitted \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\oli30\\Desktop\\11785_Intro_to_DL\\project\\auton-survival-785\\auton_survival\\models\\dsm\\utilities.py:208\u001b[0m, in \u001b[0;36mtrain_dsm\u001b[1;34m(model, x_train, t_train, e_train, x_train_normalized, x_valid, t_valid, e_valid, x_valid_normalized, n_iter, lr, elbo, bs, random_seed)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/utilities.py?line=203'>204</a>\u001b[0m \u001b[39m# print(\"train_dsm_loss: \", dsm_loss.item())\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/utilities.py?line=204'>205</a>\u001b[0m \u001b[39m# print(\"train_vae_loss: \", vae_loss.item())\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/utilities.py?line=206'>207</a>\u001b[0m loss \u001b[39m=\u001b[39m dsm_loss \u001b[39m+\u001b[39m vae_loss\n\u001b[1;32m--> <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/utilities.py?line=207'>208</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/utilities.py?line=208'>209</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/Desktop/11785_Intro_to_DL/project/auton-survival-785/auton_survival/models/dsm/utilities.py?line=210'>211</a>\u001b[0m epoch_train_dsm_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m dsm_loss\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/anaconda3/lib/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/anaconda3/lib/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/anaconda3/lib/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/anaconda3/lib/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/anaconda3/lib/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/anaconda3/lib/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/oli30/anaconda3/lib/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/anaconda3/lib/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/anaconda3/lib/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m--> <a href='file:///c%3A/Users/oli30/anaconda3/lib/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/anaconda3/lib/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/oli30/anaconda3/lib/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for param in params:\n",
    "    model = DeepSurvivalMachines(k = param['k'],\n",
    "                                 distribution = param['distribution'],\n",
    "                                 discount = param['discount'],\n",
    "                                 layers = param['layers'])\n",
    "    # The fit method is called to train the model\n",
    "    model.fit(x_train, t_train, e_train, iters = 100, learning_rate = param['learning_rate'])\n",
    "    models.append([[model.compute_nll(x_val, t_val, e_val), model]])\n",
    "best_model = min(models)\n",
    "model = best_model[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best model parameters: \")\n",
    "print(\"number of cluster: \", model.k)\n",
    "print(\"number of layers: \", model.layers)\n",
    "print(\"distribution: \", model.dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_risk = model.predict_risk(x_test, times)\n",
    "out_survival = model.predict_survival(x_test, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = x_test\n",
    "x_nm = (x - x.min(axis=0)) / (x.max(axis=0) - x.min(axis=0))\n",
    "x, x_nm = torch.from_numpy(x), torch.from_numpy(x_nm)\n",
    "_, _, z, _, _ = model.torch_model.forward(x, x_nm, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_label = torch.argmax(z, dim=1).detach().numpy()\n",
    "\n",
    "np.save('input_data.npy', x_test)\n",
    "np.save('cluster_label.npy', z_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis = []\n",
    "brs = []\n",
    "\n",
    "et_train = np.array([(e_train[i], t_train[i]) for i in range(len(e_train))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "et_test = np.array([(e_test[i], t_test[i]) for i in range(len(e_test))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "et_val = np.array([(e_val[i], t_val[i]) for i in range(len(e_val))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "\n",
    "for i, _ in enumerate(times):\n",
    "    cis.append(concordance_index_ipcw(et_train, et_test, out_risk[:, i], times[i])[0])\n",
    "brs.append(brier_score(et_train, et_test, out_survival, times)[1])\n",
    "roc_auc = []\n",
    "for i, _ in enumerate(times):\n",
    "    roc_auc.append(cumulative_dynamic_auc(et_train, et_test, out_risk[:, i], times[i])[0])\n",
    "for horizon in enumerate(horizons):\n",
    "    print(f\"For {horizon[1]} quantile,\")\n",
    "    print(\"TD Concordance Index:\", cis[horizon[0]])\n",
    "    print(\"Brier Score:\", brs[0][horizon[0]])\n",
    "    print(\"ROC AUC \", roc_auc[horizon[0]][0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
